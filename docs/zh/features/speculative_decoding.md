[English](../../features/speculative_decoding.md)

# üîÆ ÊäïÊú∫Ëß£Á†Å
Êú¨È°πÁõÆÂü∫‰∫é PaddlePaddle ÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑ **ÊäïÊú∫Ëß£Á†ÅÔºàSpeculative DecodingÔºâ** Êé®ÁêÜÊ°ÜÊû∂ÔºåÊîØÊåÅÂ§ö Token È¢ÑÊµãÔºàMulti-token Proposing, MTPÔºâÔºåÁî®‰∫éÂä†ÈÄüÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÁîüÊàêÔºåÊòæËëóÈôç‰ΩéÊó∂Âª∂Âπ∂ÊèêÂçáÂêûÂêêÈáè„ÄÇ

## ‚úÖ ÊäïÊú∫Ëß£Á†ÅÊñπÊ≥ïÊîØÊåÅ
### ‚úÖ ÊîØÊåÅÂàóË°®

- **Ngram**

- **MTP (Multi-Token Prediction)**
  - ‚úÖ Â∑≤ÊîØÊåÅÔºöTP ÂàáÂàÜ
  - ‚úÖ Â∑≤ÊîØÊåÅÔºöÂÖ±‰∫´ÂâçÁºÄ
  - ‚úÖ Â∑≤ÊîØÊåÅÔºöÂçïÊú∫ TP ÂàáÂàÜ + PD ÂàÜÁ¶ª
  - ‚è≥ Âç≥Â∞ÜÊîØÊåÅÔºöEP + DP + PD ÂàÜÁ¶ª
  - ‚è≥ Âç≥Â∞ÜÊîØÊåÅÔºöÂÖºÂÆπ Chunk Prefill
  - ‚è≥ Âç≥Â∞ÜÊîØÊåÅÔºöÂ§öÂ±Ç MTP layer

- **Ê∑∑ÂêàMTP„ÄÅNgramÊñπÊ≥ïËß£Á†Å(Hybrid-MTP-with-Ngram)**
  - ÊñπÊ≥ïÊ¶ÇËø∞ÔºöÊ∑∑ÂêàMTP‰∏éNgramÊñπÊ≥ïÔºåÂÖà‰ΩøÁî®MTP‰∫ßÂá∫N‰∏™ËçâÁ®øTokenÔºåÂÜç‰ΩøÁî®NgramÂåπÈÖçË°•ÂÖÖËçâÁ®øToken„ÄÇ
  - ‰ΩøÁî®Âú∫ÊôØÔºöÈÄÇÂêàÂú®ÈúÄË¶ÅÊõ¥Â§öËçâÁ®øTokenÊó∂‰ΩøÁî®ÔºåÂÖºÈ°æMTPÁîüÊàêËÉΩÂäõ‰∏éNgramÂåπÈÖçÁöÑÈ´òÊïàÊÄß„ÄÇ
---

### ‚è≥ ËßÑÂàí‰∏≠

- Draft Model
- Eagle
- Hydra
- Medusa
- ...

## ‚öôÔ∏è È´òÊïàÊäïÊú∫Ëß£Á†ÅÊ°ÜÊû∂ËÆæËÆ°
- **AttentionÊú∫Âà∂**ÔºöÈááÁî® [Cascade Append Attention](https://flashinfer.ai/2024/02/02/cascade-inference.html) ÁöÑ Attention Êú∫Âà∂ÔºåÊîØÊåÅÂèòÈïøÊü•ËØ¢Áªü‰∏ÄÂ§ÑÁêÜÔºå‰∏ÄÊ¨°ÂâçÂêëÊé®ÁêÜÂç≥ÂèØÂÆåÊàêÊâÄÊúâÈ™åËØÅ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂØπ Kernel ÂÆûÁé∞ËøõË°å‰∫ÜÊ∑±Â∫¶ÂÆöÂà∂Ôºå‰ª•ÊúÄÂ§ßÂåñ Tensor Core ÁöÑÂà©Áî®ÁéáÔºåÂπ∂Âú®È´òÂπ∂ÂèëÂú∫ÊôØ‰∏ã‰ªçÁÑ∂‰øùÊåÅÈ´òÂêûÂêê„ÄÇ
- **ËôöÊãüÂ°´ÂÖÖÊú∫Âà∂**ÔºöÈááÁî®ËôöÊãüÂ°´ÂÖÖÂø´ÈÄüÂÆö‰ΩçËæìÂá∫ Token ÁöÑÊâπÊ¨° IDÔºåÈÅøÂÖç‰∫ÜÈ´òÂºÄÈîÄÁöÑÊï∞ÊçÆÊã∑Ë¥ù‰∏éÂàáÁâáÊìç‰Ωú„ÄÇ
- **Âπ∂Ë°åÈááÊ†∑‰∏éÈ™åËØÅ**ÔºöÊàë‰ª¨ÂºÄÂèë‰∫ÜÂ§ö‰∏™ËûçÂêà Cuda KernelÔºåÁî®‰∫éÂêåÊó∂ÊâßË°åÈááÊ†∑‰∏éÈ™åËØÅÊìç‰Ωú„ÄÇËØ• Kernel ÊîØÊåÅÂØπÊØè‰∏™ batch Ê†∑Êú¨ËøõË°åÂπ∂Ë°åÂ§ÑÁêÜÔºåÈÅøÂÖç‰∫ÜÊòæÂºèÂæ™ÁéØÁöÑÂºÄÈîÄ„ÄÇ
- **È´òÊïà DraftModel/MTP Ê°ÜÊû∂**ÔºöÂºÄÂèëÂ§ö‰∏™ËûçÂêà Cuda KernelÔºåÁªü‰∏ÄÂÆåÊàêÊ®°ÂûãÁ±ªÊñπÊ≥ïÁöÑÂâçÂêéÂ§ÑÁêÜÔºåÁõ∏ÊØî‰º†ÁªüÁöÑÂæ™ÁéØ„ÄÅÂàáÁâáÊñπÊ≥ïÔºåÊÄßËÉΩÈ´òÊïà‰∏îÊòìÁª¥Êä§

## üîß ÂèÇÊï∞ËØ¥Êòé
- `method`: Ëß£Á†ÅÁ≠ñÁï•ÔºåÂèØÈÄâÂÄº‰∏∫ `"mtp"` Êàñ `"ngram"`
- `num_speculative_tokens`: ÊØèËΩÆÈ¢ÑÊµãÁöÑ Token Êï∞ÔºåÊúÄÂ§ßÊîØÊåÅ 5ÔºàÂΩìÂâç MTP ‰ªÖÊîØÊåÅ 1Ôºâ
- `model`: Ëã•ÈÄâÊã© MTPÔºåÂàôÈúÄÊåáÂÆö MTP Ê®°ÂûãË∑ØÂæÑ
- `quantization`: Ê®°ÂûãÈáèÂåñÊñπÂºèÔºåÊé®Ëçê‰ΩøÁî® `wint8`
- `batch_size`: ÂΩìÂâçÊîØÊåÅÊúÄÂ§ßÂÄº‰∏∫ 256

## üöÄ ‰ΩøÁî® Multi-Token-Prediction(MTP) Ëß£Á†Å
ËØ¶ËßÅËÆ∫ÊñáÔºö[DeepSeek-V3](https://arxiv.org/pdf/2412.19437)
### TP Âπ∂Ë°åÈÉ®ÁΩ≤
> ‰ΩøÁî® 4√óH100ÔºåÈáèÂåñÊñπÂºèÈÄâÊã© WINT4
> ÈÖçÁΩÆÊñá‰ª∂Ôºö`benchmarks/yaml/eb45t-32k-wint4-mtp-h100-tp4.yaml`

```
python -m fastdeploy.entrypoints.openai.api_server \
    --model ${path_to_main_model} \
    --tensor-parallel-size 4 \
    --config ${path_to_FastDeploy}benchmarks/yaml/eb45t-32k-wint4-mtp-h100-tp4.yaml \
    --speculative-config '{"method": "mtp", "num_speculative_tokens": 1, "model": "${path_to_mtp_model}"}'
```

### PD ÂàÜÁ¶ªÂºèÈÉ®ÁΩ≤Ôºà1P1DÔºâ
> Âú®8√óH100‰∏äÈÉ®ÁΩ≤1P1DÔºåP„ÄÅDËäÇÁÇπ ÂàÜÂà´‰ΩøÁî® 4√óH100ÔºõÈáèÂåñÊñπÂºèÈÄâÊã© WINT4
> ‰∏éÂ∏∏ËßÑ PD ÂàÜÁ¶ªÈÉ®ÁΩ≤‰∏ÄËá¥Ôºå‰ªÖÈúÄÊõøÊç¢ÈÖçÁΩÆÊñá‰ª∂Âπ∂Êñ∞Â¢û speculative_config
ËØ¶ÊÉÖËØ∑ÂèÇËÄÉ[PDÂàÜÁ¶ªÂºèÈÉ®ÁΩ≤](./disaggregated.md)„ÄÇ
- P ËäÇÁÇπÔºàPrefillÔºâ

> ÈÖçÁΩÆÊñá‰ª∂Ôºö `benchmarks/yaml/eb45t-32k-wint4-mtp-tp4-prefill.yaml`

```
export FD_LOG_DIR="log_prefill"
rm -rf ${FD_LOG_DIR}
export CUDA_VISIBLE_DEVICES=0,1,2,3
python -m fastdeploy.entrypoints.openai.api_server  \
       --model ${path_to_main_model} \
       --port 8180 \
       --metrics-port 8181 \
       --engine-worker-queue-port 8182 \
       --cache-queue-port 8183 \
       --workers 2 \
       --tensor-parallel-size 4 \
       --quantization wint4 \
       --splitwise-role "prefill" \
       --scheduler-name "splitwise" \
       --scheduler-host "127.0.0.1" \
       --scheduler-port 6379 \
       --scheduler-ttl 9000 \
       --scheduler-topic mtp \
       --config ${path_to_FastDeploy}/benchmarks/yaml/eb45t-32k-wint4-mtp-tp4-prefill.yaml \
       --scheduler-password "scheduler_mtp" \
       --speculative-config '{"method": "mtp", "num_speculative_tokens": 1, "model": ""${path_to_mtp_model}"}'  &
```

- D ËäÇÁÇπÔºàDecodeÔºâ

> ÈÖçÁΩÆÊñá‰ª∂Ôºö `benchmarks/yaml/eb45t-32k-wint4-mtp-tp4-decode.yaml`

```
export FD_LOG_DIR="log_prefill"
rm -rf ${FD_LOG_DIR}
export CUDA_VISIBLE_DEVICES=0,1,2,3
python -m fastdeploy.entrypoints.openai.api_server  \
       --model ${path_to_main_model} \
       --port 8180 \
       --metrics-port 8181 \
       --engine-worker-queue-port 8182 \
       --cache-queue-port 8183 \
       --workers 2 \
       --tensor-parallel-size 4 \
       --quantization wint4 \
       --splitwise-role "prefill" \
       --scheduler-name "splitwise" \
       --scheduler-host "127.0.0.1" \
       --scheduler-port 6379 \
       --scheduler-ttl 9000 \
       --scheduler-topic mtp \
       --config ${path_to_FastDeploy}/benchmarks/yaml/eb45t-32k-wint4-mtp-tp4-prefill.yaml \
       --scheduler-password "scheduler_mtp" \
       --speculative-config '{"method": "mtp", "num_speculative_tokens": 1, "model": ""${path_to_mtp_model}"}'  &
```
## ‰ΩøÁî®Ê∑∑ÂêàMTP„ÄÅNgramÊñπÊ≥ïËß£Á†Å
Âú®ÂêØÂä®ÊúçÂä°Êó∂ÔºåÂè™ÈúÄÊîπÂä® --speculative-config Âç≥ÂèØ„ÄÇ‰æãÂ¶Ç‰ΩøÁî®MTP‰∫ßÂá∫‰∏§‰∏™DraftTokenÔºåÂÜçÈ¢ùÂ§ñÊãºÊé•‰∏â‰∏™NgramÂåπÈÖçÁöÑDraftToken
```
--speculative-config '{"method": "mtp", "num_model_steps": 2, "mtp_strategy": "with_ngram" ,"num_speculative_tokens": 5, "model": "'$model_path'/mtp"}'

```
## üß† ‰ΩøÁî® Ngram Ëß£Á†Å
ËØ•ÁÆóÊ≥ïÈÄöËøá n-gram Á™óÂè£‰ªé prompt ÂíåÂ∑≤ÁîüÊàêÁöÑ Token ‰∏≠ËøõË°åÂåπÈÖçÁîüÊàêËçâÁ®ø TokenÔºåÈÄÇÂêàËæìÂÖ•ÂíåËæìÂá∫ÊúâÂæàÂ§ß overlap ÁöÑÂú∫ÊôØÔºåÂ¶Ç‰ª£Á†ÅÁª≠ÂÜô„ÄÅÊñáÊ°£Êü•ËØ¢Á≠â„ÄÇ
> ‰ΩøÁî® 4√óH100ÔºõÈáèÂåñÊñπÂºèÈÄâÊã© WINT4
> ÈÖçÁΩÆÊñá‰ª∂Ôºöbenchmarks/yaml/eb45t-32k-wint4-mtp-h100-tp4.yaml

```
python -m fastdeploy.entrypoints.openai.api_server \
    --model ${path_to_main_model} \
    --tensor-parallel-size 4 \
    --config ${path_to_FastDeploy}benchmarks/yaml/eb45t-32k-wint4-mtp-h100-tp4.yaml \
    --speculative-config '{"method": "ngram", "num_speculative_tokens": 1, "model": "${mtp_model_path}"}'
```
